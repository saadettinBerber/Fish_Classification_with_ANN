{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2170465,"sourceType":"datasetVersion","datasetId":1165452}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Giriş\n\nBu veri seti, İzmir Ekonomi Üniversitesi'nde **9** farklı deniz ürünü türüne ait segmentasyon ve **sınıflandırma** çalışmaları için toplanmıştır. Her bir tür için **1000** adet **RGB** görüntü ve bu görüntülerin karşılık gelen 1000 adet ground truth (gerçek etiket) görüntüsü bulunur. Görüntüler, iki farklı kamera ile toplanmış ve boyutları **590x445** olacak şekilde yeniden boyutlandırılmıştır. Veri seti, özellik çıkarımı, segmentasyon ve sınıflandırma algoritmalarını test etmek ve karşılaştırmak amacıyla kullanılmıştır. Biz ise sınıflandırma için kullanacağız. bir sınıf için görüntüler sıralıdır ve \"00000.png\" ile \"01000.png\" arasında adlandırılmıştır.\n\nŞimdi ise hiperparametreler üzerinden belli başlı işlemler yapılacak.\n1. 128 ve 512 gizli katmanlı modeller kıyaslanacak.\n2. Dropout değeri \"0.5\" ve \"0.7\" yapılıp kıyaslanacak\n3. Optimizasyon olarak hali hazırda kullanılan **Adam** algoritması **SGD** ile kıyaslanacak \n4. (giriş_boyutu, 512, 128, kategori_sayısı-9- ) katmanlı model eğitilecek\n5. En sonda ise eğitilen tüm modeller kıyaslanacak\n\nİlk önce gerekli kütüphaneleri **içeri aktaralım**. (import)","metadata":{}},{"cell_type":"markdown","source":"## Kütüphaneleri İçe Aktarma","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image  # Görselleri okumak için gerekli kütüphane\nimport matplotlib.pyplot as plt\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nimport numpy as np\n\n# Uyarıların gizlenmesi\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#Tüm sütunları görebilmek için tabloyu ayarladık.\npd.set_option('display.max_colwidth', 1000)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:33.822985Z","iopub.execute_input":"2024-10-23T18:34:33.823451Z","iopub.status.idle":"2024-10-23T18:34:38.201798Z","shell.execute_reply.started":"2024-10-23T18:34:33.823385Z","shell.execute_reply":"2024-10-23T18:34:38.200417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Veri Setini ----> Pandas DataFrame\n\nBu kod, bir dosya sisteminde bulunan deniz mahsulleri görsellerinin dosya yollarını ve etiketlerini toplar ve bu verileri pandas kütüphanesinin DataFrame yapısına çevirir. DataFrame kullanmamızın sebebi, veriyi ön incelemede daha kolay ve rahat bir şekilde ele almamızı sağlamasıdır.\n","metadata":{}},{"cell_type":"code","source":"label = []                    #Deniz mahsülünün hangi etikette olduğunu belirten liste\npath = []                     #Deniz mahsül görselinin adres yolu\n\nfish_dir = '/kaggle/input/a-large-scale-fish-dataset/Fish_Dataset/Fish_Dataset'\n\n# Verileri klasörlerden toplayarak her tür için görselleri ve etiketleri alıyoruz\nfor dir_name, _, filenames in os.walk(fish_dir):\n    for filename in filenames:\n        if os.path.splitext(filename)[-1] == '.png':          # Görselleri sınıflandıracağımız için sadece .png dosyalarını alıyoruz\n            if dir_name.split()[-1] != 'GT':                   # Seegmentasyon değil de sınıflandırma yaptığımız için ground truth etiketlerine ihtiyacımız yok.\n                file_path = os.path.join(dir_name, filename)\n                label.append(os.path.split(dir_name)[-1])  # Adres yolunun adından deniz mahsülünün etiketini elde ediyoruz.\n                path.append(file_path)  # Dosya yolunu kaydediyoruz\n\n# Etiket ve dosya yollarından bir DataFrame oluşturuyoruz\ndata = pd.DataFrame(columns=['path', 'label'])\ndata['path'] = path\ndata['label'] = label\n\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:38.203763Z","iopub.execute_input":"2024-10-23T18:34:38.204273Z","iopub.status.idle":"2024-10-23T18:34:38.403501Z","shell.execute_reply.started":"2024-10-23T18:34:38.204231Z","shell.execute_reply":"2024-10-23T18:34:38.402322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Keşifsel Veri Analizi\n\nVeri setindeki hangi deniz mahsülleri ve kaç tane var inceleyelim. \n\n* 9 tane kategori var ve her birinden bin tane örnek bulunmaktadır. ","metadata":{}},{"cell_type":"code","source":"data[\"label\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:38.405268Z","iopub.execute_input":"2024-10-23T18:34:38.405797Z","iopub.status.idle":"2024-10-23T18:34:38.419382Z","shell.execute_reply.started":"2024-10-23T18:34:38.405741Z","shell.execute_reply":"2024-10-23T18:34:38.418106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Boş Değer Kontrolü\n\nBu kod parçası, path ve label sütunlarında eksik (boş) değer olup olmadığını analiz eder. Eksik değerler veri temizleme sürecinde önemli bir adımdır, çünkü makine öğrenmesi modelleri eksik veri içeren kayıtlarla doğru çalışamayabilir.","metadata":{}},{"cell_type":"code","source":"# \"path\" ve \"label\" sütunlarında eksik değerleri yazdırıyoruz\nprint(f\"Boş path sayısı: {data['path'].isnull().sum()}\")\nprint(f\"Boş label sayısı: {data['label'].isnull().sum()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:38.423025Z","iopub.execute_input":"2024-10-23T18:34:38.423452Z","iopub.status.idle":"2024-10-23T18:34:38.433665Z","shell.execute_reply.started":"2024-10-23T18:34:38.423398Z","shell.execute_reply":"2024-10-23T18:34:38.432368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:38.435311Z","iopub.execute_input":"2024-10-23T18:34:38.435797Z","iopub.status.idle":"2024-10-23T18:34:38.468147Z","shell.execute_reply.started":"2024-10-23T18:34:38.435755Z","shell.execute_reply":"2024-10-23T18:34:38.466840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Veri Setinin Görselleştirilmesi\nVeri setindeki her bir kategoriden en az bir tane deniz mahsulü örneğini seçip görselleştirelim. İlk olarak, her kategoriden bir örnek alınır ve görselleri göstermek için 3x3'lük bir grid yapısı oluşturulur. Her görselin üzerinde, görselin kategorisini gösteren bir başlık bulunur. Bu işlem, veri setindeki her bir kategoriden en az bir tane deniz mahsulünü incelememizi sağlar.","metadata":{}},{"cell_type":"code","source":"# Her kategoriden bir tane örnek seçiyoruz\nsample_data = data.groupby('label').apply(lambda x: x.iloc[0]).reset_index(drop=True)\n\n# Görselleri görselleştirmek için bir ızgara (grid) oluşturuyoruz\nplt.figure(figsize=(12, 12))  # Grafik boyutunu ayarlıyoruz\n\nfor idx, row in sample_data.iterrows():\n    # Görselleri açıyoruz\n    img = Image.open(row['path'])\n    \n    # 3x3'lük bir grid yapısı oluşturuyoruz\n    plt.subplot(3, 3, idx + 1)  # 3 satır, 3 sütun, sırayla her bir görsel\n    plt.imshow(img)\n    plt.axis('off')  # Eksenleri kapatıyoruz\n    plt.title(row['label'])  # Başlık olarak etiketi ekliyoruz\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:38.470257Z","iopub.execute_input":"2024-10-23T18:34:38.470769Z","iopub.status.idle":"2024-10-23T18:34:40.789352Z","shell.execute_reply.started":"2024-10-23T18:34:38.470710Z","shell.execute_reply":"2024-10-23T18:34:40.786905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Frekansı Görselleştirme\n\nGörselleştirme, veri setinin dengeli bir şekilde dağılmış olup olmadığını anlamak açısından önemlidir. \"Veri seti dengeli bir şekilde dağılmış\" ifadesi, tüm sınıfların eşit veya yakın sayılarda örneklere sahip olduğunu gösterir, bu da sınıflandırma modelleri için önemlidir çünkü dengesiz bir veri seti modelin bazı sınıflarda kötü performans göstermesine yol açabilir.","metadata":{}},{"cell_type":"code","source":"# Frekansları saymak için:\nlabel_counts = data[\"label\"].value_counts()\n\n# 1. Sütun Grafiği (Bar Plot)\nplt.figure(figsize=(8, 6))\nlabel_counts.plot(kind='bar', color='skyblue')\nplt.title('Deniz Mahsülleri Sınıflarının Sütun Grafiği')\nplt.xlabel('Label')\nplt.ylabel('Frekans')\nplt.show()\n\n# 2. Pasta Grafiği (Pie Chart)\nplt.figure(figsize=(8, 6))\nlabel_counts.plot(kind='pie', autopct='%1.1f%%', startangle=90, colors=plt.cm.Paired.colors)\nplt.title('Deniz Mahsülleri Sınıflarının Pasta Grafiği')\nplt.ylabel('')  # Y eksenini kaldırıyoruz\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:40.791144Z","iopub.execute_input":"2024-10-23T18:34:40.791634Z","iopub.status.idle":"2024-10-23T18:34:41.416668Z","shell.execute_reply.started":"2024-10-23T18:34:40.791584Z","shell.execute_reply":"2024-10-23T18:34:41.415022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Veri Setini Ayırma\n\nModelimizin örüntüleri öğrenebilmesi için, veri setini eğitim, doğrulama ve test kümelerine her bir kategoriden eşit sayıda örnek olacak şekilde bölmemiz gerekiyor. Bunu yaparken:\n\n1. Eğitim, doğrulama ve test kümeleri, sırasıyla 8:1:1 oranında ayrılacak.\n2. Veri seti karıştırılacak (shuffle) ve böylece dağılımın rastgele olmasını sağlayacağız.\n3. Bu oranları dikkate alarak, her bir deniz mahsulü kategorisini eğitim, doğrulama ve test kümelerine ayıracağız.\n\nKodda **shuffle** fonksiyonu, verilerin karışmasını sağlayarak modelin öğrenme sırasında veri sıralamasından etkilenmesini önler","metadata":{}},{"cell_type":"code","source":"train_ratio, validation_ratio, test_ratio = 0.8 , 0.1 , 0.1\n\n# Shuffle edilen DataFrame\nshuffled_data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n\n# Boş bir 'split' sütunu oluşturuyoruz\nshuffled_data['split'] = np.nan\n\n# Kategoriler üzerinde döngü\nfor category in shuffled_data['label'].unique():\n    # Her kategoriye ait verileri seçiyoruz\n    category_data = shuffled_data[shuffled_data['label'] == category]\n    \n    # Kategoriyi shuffle ediyoruz\n    category_data = category_data.sample(frac=1, random_state=42)\n    \n    # Her kategori için oranlara göre ayırıyoruz (%70 train, %15 val, %15 test)\n    train_size = int(train_ratio * len(category_data))\n    val_size = int(validation_ratio * len(category_data))\n    \n    # Kategorinin ilk %70'ini 'train', sonraki %15'ini 'val', kalanını 'test' olarak etiketliyoruz\n    shuffled_data.loc[category_data.index[:train_size], 'split'] = 'train'\n    shuffled_data.loc[category_data.index[train_size:train_size + val_size], 'split'] = 'val'\n    shuffled_data.loc[category_data.index[train_size + val_size:], 'split'] = 'test'\n\n# Boş kalan satırları kontrol ediyoruz\nempty_rows = shuffled_data[shuffled_data['split'].isna()]\nprint(f\"Boş kalan satır sayısı: {len(empty_rows)}\")\n\n# Sonuçları inceleyelim\nprint(shuffled_data['split'].value_counts())  # Kaç tane train, val, test var görelim\nprint(shuffled_data.head())  # İlk birkaç satırı kontrol edelim","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:41.418279Z","iopub.execute_input":"2024-10-23T18:34:41.418685Z","iopub.status.idle":"2024-10-23T18:34:41.489371Z","shell.execute_reply.started":"2024-10-23T18:34:41.418631Z","shell.execute_reply":"2024-10-23T18:34:41.488236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CustomDataset Sınıfı\n\n* Bu kod parçası, PyTorch'un veri işleme altyapısında kullanılan **Dataset** sınıfından türetilen CustomDataset sınıfını tanımlar ve görsellerin dosya yollarını ve etiketlerini alarak gerektiğinde veri dönüşümleri uygulamayı sağlar. \n* Bu sınıf, üç temel yöntem olan __init__, __len__ ve __getitem__ fonksiyonları ile veri setine esnek ve kolay erişim sunar.\n* **Transform** parametresi, her veri noktasına özel dönüşüm uygulamayı sağlayarak boyutlandırma, normalize etme gibi veri ön işleme işlemlerini kolaylaştırır. Bu yapı, çeşitli veri setlerini (örneğin görseller) işlemek için esneklik sunar\n*  Veri yükleme sırasında modelin ihtiyaç duyduğu her bir veri örneğine __getitem__ fonksiyonu aracılığıyla erişim sağlar.","metadata":{}},{"cell_type":"code","source":"# Custom Dataset Sınıfı\nclass CustomDataset(Dataset):\n    def __init__(self, file_paths, labels, transform=None):\n        self.file_paths = file_paths  # Görsel dosya yolları\n        self.labels = labels          # Etiketler\n        self.transform = transform    # Dönüştürme işlemleri\n\n    def __len__(self):\n        return len(self.file_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.file_paths[idx]  # Görsel dosya yolu\n        label = self.labels[idx]         # Etiket\n        \n        # Görseli açıyoruz\n        image = Image.open(img_path).convert(\"RGB\")\n        \n        # Transform işlemi uygulanırsa\n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:41.490970Z","iopub.execute_input":"2024-10-23T18:34:41.491353Z","iopub.status.idle":"2024-10-23T18:34:41.500789Z","shell.execute_reply.started":"2024-10-23T18:34:41.491314Z","shell.execute_reply":"2024-10-23T18:34:41.499706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# One Hot Encoding\n\n* Makine öğrenmesi modelleri, kategorik verilerle doğrudan çalışamadığından, bu tür verilerin sayısal formatlara dönüştürülmesi gerekir.\n*  **pd.factorize()** kullanarak etiketleri sayısallaştırmak, modelin bu verilerle işlemler yapmasına olanak tanır ve böylece sınıflandırma problemlerinde verinin işlenmesi daha kolay hale gelir. \n\n* Bu yöntem aynı zamanda verinin kolayca geri dönüştürülebilir (sayısal etiketten orijinal etikete) olmasını sağlar.","metadata":{}},{"cell_type":"code","source":"shuffled_data['label_encoded'], label_mapping = pd.factorize(shuffled_data['label'])","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:41.505318Z","iopub.execute_input":"2024-10-23T18:34:41.506064Z","iopub.status.idle":"2024-10-23T18:34:41.521695Z","shell.execute_reply.started":"2024-10-23T18:34:41.506020Z","shell.execute_reply":"2024-10-23T18:34:41.520398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shuffled_data.head(), label_mapping","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:41.523050Z","iopub.execute_input":"2024-10-23T18:34:41.523439Z","iopub.status.idle":"2024-10-23T18:34:41.536885Z","shell.execute_reply.started":"2024-10-23T18:34:41.523398Z","shell.execute_reply":"2024-10-23T18:34:41.535634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DataFrame ---> List\n\nBu kod parçası, DataFrame yapısında bulunan train, validation ve test kümelerine ait dosya yolları ve etiketleri, iteratif işlemler yapabilmek için liste formatına dönüştürür.","metadata":{}},{"cell_type":"code","source":"# Train, Validation ve Test dosya yolları ve etiketlerini DataFrame'den çekiyoruz\ntrain_file_paths = shuffled_data[shuffled_data['split'] == 'train']['path'].tolist()\ntrain_labels = shuffled_data[shuffled_data['split'] == 'train']['label_encoded'].tolist()\n\nval_file_paths = shuffled_data[shuffled_data['split'] == 'val']['path'].tolist()\nval_labels = shuffled_data[shuffled_data['split'] == 'val']['label_encoded'].tolist()\n\ntest_file_paths = shuffled_data[shuffled_data['split'] == 'test']['path'].tolist()\ntest_labels = shuffled_data[shuffled_data['split'] == 'test']['label_encoded'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:41.538397Z","iopub.execute_input":"2024-10-23T18:34:41.538817Z","iopub.status.idle":"2024-10-23T18:34:41.564854Z","shell.execute_reply.started":"2024-10-23T18:34:41.538757Z","shell.execute_reply":"2024-10-23T18:34:41.563753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hiperparametreler\n\nBu hiperparametreler, görüntü sınıflandırma problemine uygun olarak ayarlanmıştır. \n* **input_size** 64x64 piksel boyutundaki RGB resimlerden gelen 12,288 giriş biriminden oluşur, bu boyut hem modelin hızlı çalışmasını sağlar hem de yeterli detay sunar. \n* **output_size**, veri setindeki 9 farklı deniz mahsulü sınıfını temsil eder ve modelin bu sınıflardan birini tahmin etmesi beklenir.\n* **epochs** ise modelin eğitim sürecinde veri seti üzerinde 15 kez geçiş yapacağını ifade eder, bu sayede model yeterli öğrenmeyi sağlayacak şekilde eğitilir.","metadata":{}},{"cell_type":"code","source":"input_size = 64 * 64 * 3  # 64x64 boyutunda ve 3 kanallı (RGB) bir resim\noutput_size = 9  # 9 sınıflı bir sınıflandırma problemi\nepochs = 15","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:41.566319Z","iopub.execute_input":"2024-10-23T18:34:41.566753Z","iopub.status.idle":"2024-10-23T18:34:41.572497Z","shell.execute_reply.started":"2024-10-23T18:34:41.566707Z","shell.execute_reply":"2024-10-23T18:34:41.571234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CustomDataset Nesneleri\n\nBu kod parçasında, tüm görsellerin boyutu önce 590x445 olarak normalize edilmiştir, ancak yeterli donanım kaynağı olmadığı için işlem gücünü optimize etmek amacıyla boyut 64x64 olarak ayarlanmıştır. Görsellerin yeniden boyutlandırılması transforms.Resize((64, 64)) ile yapılır, ardından görseller ToTensor() ile tensöre dönüştürülür. Son olarak, her pikselin değerleri Normalize() fonksiyonu ile [0.5, 0.5, 0.5] ortalamaları ve [0.5, 0.5, 0.5] standart sapmaları kullanılarak normalize edilir. Bu dönüşümler, modelin daha verimli çalışmasını sağlamak için uygulanır.","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((64, 64)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\n# Dataset'leri oluşturma\ntrain_dataset = CustomDataset(train_file_paths, train_labels, transform=transform)\nval_dataset = CustomDataset(val_file_paths, val_labels, transform=transform)\ntest_dataset = CustomDataset(test_file_paths, test_labels, transform=transform)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:41.574094Z","iopub.execute_input":"2024-10-23T18:34:41.574471Z","iopub.status.idle":"2024-10-23T18:34:41.585769Z","shell.execute_reply.started":"2024-10-23T18:34:41.574432Z","shell.execute_reply":"2024-10-23T18:34:41.584518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DataLoader\n\n**DataLoader** fonksiyonu, PyTorch'un veri işleme süreçlerinde kullanılan ve veri kümelerini daha verimli bir şekilde işlemenizi sağlayan bir araçtır. DataLoader, veri kümesini **batch** adı verilen **küçük parçalara** bölerek modele aktarır, böylece modelin aynı anda **büyük** bir veri kümesini **bellekte** tutmasına gerek **kalmaz**. Ayrıca, veri yüklemesini paralel olarak yaparak işlem hızını artırır ve her eğitim döngüsünde verilerin **rastgele karıştırılmasını** (shuffle) sağlayarak modelin **aşırı öğrenmesini** önler.\n\nDataLoader ile **CustomDataset sınıfı** arasındaki ilişki ise şu şekildedir: CustomDataset, verilerin nasıl yükleneceğini ve ön işlemlerden geçeceğini belirlerken, DataLoader bu veri kümesini iteratif olarak işler ve modele beslenmek üzere hazırlar. ","metadata":{}},{"cell_type":"code","source":"# DataLoader ile veri yükleme\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:41.587086Z","iopub.execute_input":"2024-10-23T18:34:41.587467Z","iopub.status.idle":"2024-10-23T18:34:41.603476Z","shell.execute_reply.started":"2024-10-23T18:34:41.587428Z","shell.execute_reply":"2024-10-23T18:34:41.601959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Kontrol etmek için sadece 1 tane veriye bakalım\nfor images, labels in train_loader:\n    print(f\"Görüntülerin şekli: {images.shape}\")\n    print(f\"Etiketlerin şekli: {labels.shape}\")\n    break","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:41.605104Z","iopub.execute_input":"2024-10-23T18:34:41.605579Z","iopub.status.idle":"2024-10-23T18:34:42.080691Z","shell.execute_reply.started":"2024-10-23T18:34:41.605523Z","shell.execute_reply":"2024-10-23T18:34:42.079545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sinir Ağı Oluşturma Fonksiyon\n\nBu fonksiyon, birden fazla modeli esnek bir şekilde oluşturup karşılaştırmak için yazılmıştır. Farklı sayıda gizli katmana sahip modellerin kolayca tanımlanmasını ve aynı yapı üzerinden çeşitli parametrelerle model oluşturulmasını sağlar. Özellikle, input_size, output_size, hidden_layers ve dropout_rate gibi hiperparametreler dinamik olarak değiştirilebilir, böylece kullanıcı farklı yapıdaki modelleri hızlıca deneyebilir. Fonksiyonda kullanılan:\n\n* **Flatten** katmanı, görsel veriyi düzleştirerek 1D vektöre dönüştürür; Linear katmanlar, nöronlar arasında tam bağlantılı sinir ağı kurarak bilgiyi aktarır. \n* **ReLU** aktivasyon fonksiyonu, doğrusal olmayan bir ilişki ekleyerek modelin daha karmaşık örüntüleri öğrenmesini sağlar.\n* **Dropout** katmanı, aşırı öğrenmeyi (overfitting) önlemek için rastgele nöronları devre dışı bırakır.\n* **Softmax** katmanı, çıkışları olasılık dağılımına dönüştürerek çok sınıflı sınıflandırma problemlerinde her sınıfa ait olasılık tahmini yapar.\n\nBu fonksiyon sayesinde, manuel model tanımlamalarına gerek kalmadan farklı katman yapıları ve dropout oranları ile modeller oluşturulabilir, eğitilebilir ve karşılaştırılabilir.","metadata":{}},{"cell_type":"code","source":"# create_model fonksiyonu: dinamik olarak Sequential yapı oluşturur, Dropout ve Flatten eklenmiş\ndef create_model(input_size, output_size, hidden_layers, dropout_rate=0.5):\n    layers = []\n    \n    # Flatten katmanını ekle (görsel veriyi 1D vektöre dönüştürmek için)\n    layers.append(nn.Flatten())\n    \n    # Giriş katmanını ekle (input_size -> hidden_layers[0])\n    layers.append(nn.Linear(input_size, hidden_layers[0]))\n    layers.append(nn.ReLU())  # Aktivasyon fonksiyonu\n    layers.append(nn.Dropout(dropout_rate))  # Dropout\n    \n    # Gizli katmanları ekle\n    for i in range(len(hidden_layers) - 1):\n        layers.append(nn.Linear(hidden_layers[i], hidden_layers[i + 1]))\n        layers.append(nn.ReLU())  # Her katmana ReLU ekle\n        layers.append(nn.Dropout(dropout_rate))  # Dropout\n    \n    # Çıkış katmanını ekle (hidden_layers[-1] -> output_size)\n    layers.append(nn.Linear(hidden_layers[-1], output_size))\n    \n    # Çıkış için Softmax fonksiyonunu ekle\n    layers.append(nn.Softmax(dim=1))\n    \n    # Sequential modeli oluştur ve döndür\n    return nn.Sequential(*layers)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:42.082324Z","iopub.execute_input":"2024-10-23T18:34:42.082757Z","iopub.status.idle":"2024-10-23T18:34:42.093180Z","shell.execute_reply.started":"2024-10-23T18:34:42.082714Z","shell.execute_reply":"2024-10-23T18:34:42.091852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Doğrulama Fonksiyonu\n\nBu fonksiyon, modelin **doğrulama kümesi** üzerindeki performansını değerlendirmek için kullanılır. **validate** fonksiyonu, doğrulama verileriyle modeli test ederken gradyan hesaplamayı kapatır, doğrulama kaybını (loss) ve doğruluk oranını (accuracy) hesaplayıp geri döndürür.","metadata":{}},{"cell_type":"code","source":"def validate(model, val_loader, criterion, device):\n    model.eval()  # Modeli doğrulama moduna geçiriyoruz\n    val_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():  # Gradyan hesaplamaya gerek yok\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    return val_loss / len(val_loader), accuracy\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:42.094785Z","iopub.execute_input":"2024-10-23T18:34:42.095180Z","iopub.status.idle":"2024-10-23T18:34:42.106028Z","shell.execute_reply.started":"2024-10-23T18:34:42.095141Z","shell.execute_reply":"2024-10-23T18:34:42.104949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Eğitim İçin Fonksiyonlar\n\nBu iki fonksiyon, modelin eğitim ve doğrulama süreçlerini yönetmek için kullanılır.\n* **train_one_epoch** fonksiyonu, modelin bir epoch boyunca eğitim verisi üzerinde eğitilmesini sağlar.\n*  **train_model** fonksiyonu ise bu süreci birden fazla epoch boyunca tekrarlar,","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, train_loader, criterion, optimizer, device):\n    model.train()  # Modeli eğitim moduna geçiriyoruz\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()  # Gradyanları sıfırla\n        outputs = model(images)  # İleri geçiş (forward pass)\n        loss = criterion(outputs, labels)  # Kayıp hesapla\n        loss.backward()  # Geri yayılım (backward pass)\n        optimizer.step()  # Optimizasyonu uygula\n\n        running_loss += loss.item()\n\n        _, predicted = torch.max(outputs, 1)  # Tahmin edilen sınıf\n        total += labels.size(0)  # Toplam örnek sayısı\n        correct += (predicted == labels).sum().item()  # Doğru tahmin sayısı\n\n    # Eğitim seti üzerindeki doğruluğu hesaplıyoruz\n    accuracy = 100 * correct / total\n\n    # Ortalama eğitim kaybı ve doğruluk döndürülüyor\n    return running_loss / len(train_loader), accuracy\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:42.107524Z","iopub.execute_input":"2024-10-23T18:34:42.108032Z","iopub.status.idle":"2024-10-23T18:34:42.126810Z","shell.execute_reply.started":"2024-10-23T18:34:42.107977Z","shell.execute_reply":"2024-10-23T18:34:42.125417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n    train_loss_arr = []\n    train_accurracy_arr = []\n    val_loss_arr = []\n    val_accuracy_arr = []\n    for epoch in range(num_epochs):\n        train_loss, accuracy = train_one_epoch(model, train_loader, criterion, optimizer, device)\n        val_loss, val_accuracy = validate(model, val_loader, criterion, device)\n        \n        train_loss_arr.append(train_loss)\n        train_accurracy_arr.append(accuracy)\n        val_loss_arr.append(val_loss)\n        val_accuracy_arr.append(val_accuracy)\n        \n        print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n              f\"Train Loss: {train_loss:.4f}, \"\n              f\"Validation Loss: {val_loss:.4f}, \"\n              f\"Validation Accuracy: {val_accuracy:.2f}%\")\n    return train_loss_arr, train_accurracy_arr, val_loss_arr, val_accuracy_arr","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:42.129011Z","iopub.execute_input":"2024-10-23T18:34:42.129441Z","iopub.status.idle":"2024-10-23T18:34:42.140447Z","shell.execute_reply.started":"2024-10-23T18:34:42.129395Z","shell.execute_reply":"2024-10-23T18:34:42.139236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Fonksiyonu\n\nBu fonksiyon, modelin test verisi üzerindeki performansını değerlendirmek için kullanılır. Test sırasında modelin tahminleri ile gerçek etiketler toplanır ve test işlemi gerçekleştirilir. Sonuç olarak, gerçek ve tahmin edilen etiketler döndürülerek modelin başarımı analiz edilir.","metadata":{}},{"cell_type":"code","source":"# Eval fonksiyonu modelin test performansını ölçer\ndef test_model(model, data_loader, criterion, device):\n    model.eval()\n    all_labels = []\n    all_predictions = []\n\n    with torch.no_grad():\n        for images, labels in data_loader:\n            images = images.view(images.size(0), -1).to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n\n            all_labels.extend(labels.cpu().numpy())  # Gerçek etiketler\n            all_predictions.extend(predicted.cpu().numpy())  # Tahmin edilenler\n\n    return all_labels, all_predictions","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:42.141846Z","iopub.execute_input":"2024-10-23T18:34:42.142197Z","iopub.status.idle":"2024-10-23T18:34:42.157821Z","shell.execute_reply.started":"2024-10-23T18:34:42.142161Z","shell.execute_reply":"2024-10-23T18:34:42.156612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Başarı Metrikleri\n\nAccuracy, Recall, Precision ve F1-Score, sınıflandırma modelinin performansını değerlendiren temel metriklerdir. \n* **Accuracy**, modelin doğru tahmin ettiği örneklerin tüm örnekler içerisindeki oranını gösterir ve genel performansı ölçer, ancak sınıf dengesizliği olduğunda yanıltıcı olabilir.\n* **Recall**, modelin pozitif sınıfları ne kadar iyi yakaladığını, yani gerçek pozitiflerin ne kadarının doğru tahmin edildiğini ölçer.\n* **Precision**, pozitif olarak tahmin edilen örneklerin gerçekten pozitif olma oranını gösterir ve modelin yanlış pozitifleri azaltma başarısını değerlendirir.\n* **F1-Score**, Recall ve Precision'ın harmonik ortalamasıdır ve bu iki metrik arasında denge sağlamak için kullanılır, özellikle dengesiz veri setlerinde faydalıdır.\n\n\nBu metrikler bir arada kullanılarak modelin sınıflandırma performansı daha detaylı bir şekilde anlaşılabilir.","metadata":{}},{"cell_type":"code","source":"# Tüm modellerin çıktıları dataframe yapısında saklanacak.\n# Ondan all_result diye değişken tanımlandı\nall_result = pd.DataFrame(columns=['Model', 'Accuracy', 'Recall', 'Precision', 'F1-Score'])","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:42.159980Z","iopub.execute_input":"2024-10-23T18:34:42.160426Z","iopub.status.idle":"2024-10-23T18:34:42.171305Z","shell.execute_reply.started":"2024-10-23T18:34:42.160382Z","shell.execute_reply":"2024-10-23T18:34:42.170162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def metrics(model_name, model, data_loader, criterion, device, class_names):\n    global all_result  # Global DataFrame'i kullanıyoruz\n    \n    # Eval fonksiyonu ile gerçek ve tahmin edilen etiketleri alıyoruz\n    true_labels, predicted_labels = test_model(model, data_loader, criterion, device)\n\n    # Classification Report oluşturma\n    report = classification_report(true_labels, predicted_labels, target_names=class_names, output_dict=True)\n    \n    # Confusion Matrix oluşturma\n    cm = confusion_matrix(true_labels, predicted_labels)\n    \n    # Confusion Matrix'i görselleştirme\n    plt.figure(figsize=(10, 7))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel('Predicted Labels')\n    plt.ylabel('True Labels')\n    plt.title(f'Confusion Matrix - {model_name}')\n    plt.show()\n    \n    # Sonuçları DataFrame'e eklemek için dictionary oluşturuyoruz\n    result = pd.DataFrame([{\n        'Model': model_name,\n        'Accuracy': report['accuracy'],\n        'Recall': report['weighted avg']['recall'],\n        'Precision': report['weighted avg']['precision'],\n        'F1-Score': report['weighted avg']['f1-score']\n    }])\n    \n    # Global DataFrame'e sonuçları concat ile ekliyoruz\n    all_result = pd.concat([all_result, result], ignore_index=True)\n    \n    # Sonuçları ekrana yazdırıyoruz\n    print(f\"Model: {model_name}\")\n    print(f\"Accuracy: {report['accuracy']}\")\n    print(f\"Recall: {report['weighted avg']['recall']}\")\n    print(f\"Precision: {report['weighted avg']['precision']}\")\n    print(f\"F1-Score: {report['weighted avg']['f1-score']}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:42.172864Z","iopub.execute_input":"2024-10-23T18:34:42.173326Z","iopub.status.idle":"2024-10-23T18:34:42.186615Z","shell.execute_reply.started":"2024-10-23T18:34:42.173270Z","shell.execute_reply":"2024-10-23T18:34:42.185083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Görselleştirme Fonksiyonu (Loss ve Acc)\n\nDoğrulama ve eğitim sürecindeki loss ve accuracy değerlerini daha iyi değerlendirmek için yardımcı fonksiyon.","metadata":{}},{"cell_type":"code","source":"def plot_training_curves(train_loss, val_loss, train_accuracy, val_accuracy):\n    epochs = range(1, len(train_loss) + 1)\n\n    # Loss grafiği\n    plt.figure(figsize=(12, 5))\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, train_loss, 'b', label='Train Loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n    plt.title('Loss per Epoch')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    # Accuracy grafiği\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, train_accuracy, 'b', label='Train Accuracy')\n    plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n    plt.title('Accuracy per Epoch')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:42.188069Z","iopub.execute_input":"2024-10-23T18:34:42.188470Z","iopub.status.idle":"2024-10-23T18:34:42.204386Z","shell.execute_reply.started":"2024-10-23T18:34:42.188428Z","shell.execute_reply":"2024-10-23T18:34:42.203027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Device","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:42.205938Z","iopub.execute_input":"2024-10-23T18:34:42.206327Z","iopub.status.idle":"2024-10-23T18:34:42.220979Z","shell.execute_reply.started":"2024-10-23T18:34:42.206286Z","shell.execute_reply":"2024-10-23T18:34:42.219674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 128 Katmanlı Model\n","metadata":{}},{"cell_type":"code","source":"hidden_layers = [128]  # Gizli katmanlar\ndropout_rate = 0.5  # Dropout oranı\n\n# create_model fonksiyonu ile modeli oluştur\nmodel_128 = create_model(input_size, output_size, hidden_layers, dropout_rate)\n\n# Modeli kontrol etmek için yapı bilgilerini yazdır\nprint(model_128)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:42.222296Z","iopub.execute_input":"2024-10-23T18:34:42.222694Z","iopub.status.idle":"2024-10-23T18:34:42.252854Z","shell.execute_reply.started":"2024-10-23T18:34:42.222616Z","shell.execute_reply":"2024-10-23T18:34:42.251625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_128 = model_128.to(device)\n\n# Kayıp fonksiyonu ve optimizer tanımlama\ncriterion = nn.CrossEntropyLoss()\noptimizer_128 = torch.optim.Adam(model_128.parameters(), lr=0.001)\n\n# 128 nöronlu modelin eğitim aşaması\ntrain_loss_arr_128, train_accuracy_arr_128, val_loss_arr_128, val_accuracy_arr_128 = train_model(\n    model_128, train_loader, val_loader, criterion, optimizer_128, num_epochs=epochs, device=device)\n\n# Eğitim sonuçlarını görselleştirme\nplot_training_curves(train_loss_arr_128, val_loss_arr_128, train_accuracy_arr_128, val_accuracy_arr_128)\n\n# 128 nöronlu modelin sonuçlarını hesaplayalım\nmetrics(\"model_128\", model_128, test_loader, criterion, device, label_mapping)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T18:34:42.254516Z","iopub.execute_input":"2024-10-23T18:34:42.255023Z","iopub.status.idle":"2024-10-23T19:04:29.467879Z","shell.execute_reply.started":"2024-10-23T18:34:42.254964Z","shell.execute_reply":"2024-10-23T19:04:29.466613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 512 Katmanlı Model","metadata":{}},{"cell_type":"code","source":"hidden_layers = [512]  # Gizli katmanlar\ndropout_rate = 0.5  # Dropout oranı\n\n# create_model fonksiyonu ile modeli oluştur\nmodel_512 = create_model(input_size, output_size, hidden_layers, dropout_rate)\n\n# Modeli kontrol etmek için yapı bilgilerini yazdır\nprint(model_512)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T19:04:29.475121Z","iopub.execute_input":"2024-10-23T19:04:29.475837Z","iopub.status.idle":"2024-10-23T19:04:29.554490Z","shell.execute_reply.started":"2024-10-23T19:04:29.475790Z","shell.execute_reply":"2024-10-23T19:04:29.553213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_512 = model_512.to(device)\n\n# Kayıp fonksiyonu ve optimizer tanımlama\ncriterion = nn.CrossEntropyLoss()\noptimizer_512 = torch.optim.Adam(model_512.parameters(), lr=0.001)\n\n# 512 nöronlu modelin eğitim aşaması\ntrain_loss_arr_512, train_accuracy_arr_512, val_loss_arr_512, val_accuracy_arr_512 = train_model(\n    model_512, train_loader, val_loader, criterion, optimizer_512, num_epochs=epochs, device=device)\n\n# Eğitim sonuçlarını görselleştirme\nplot_training_curves(train_loss_arr_512, val_loss_arr_512, train_accuracy_arr_512, val_accuracy_arr_512)\nmetrics(\"model_512\", model_512, test_loader, criterion, device, label_mapping)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T19:04:29.555855Z","iopub.execute_input":"2024-10-23T19:04:29.556225Z","iopub.status.idle":"2024-10-23T19:36:40.963055Z","shell.execute_reply.started":"2024-10-23T19:04:29.556186Z","shell.execute_reply":"2024-10-23T19:36:40.961759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 0.7 Dropout Model","metadata":{}},{"cell_type":"code","source":"# 128 Nöronlu Model (Dropout 0.7)\nhidden_layers = [128]  # Gizli katmanlar\ndropout_rate = 0.7  # Dropout oranı\n\n# create_model fonksiyonu ile modeli oluştur\nmodel_128_dropout_07 = create_model(input_size, output_size, hidden_layers, dropout_rate)\n\n# Modeli cihaza aktar\nmodel_128_dropout_07 = model_128_dropout_07.to(device)\n\n# Kayıp fonksiyonu ve optimizer tanımlama\noptimizer_128_dropout_07 = torch.optim.Adam(model_128_dropout_07.parameters(), lr=0.001)\n\n# 128 nöronlu modelin eğitim aşaması (dropout 0.7)\ntrain_loss_arr_128_07, train_accuracy_arr_128_07, val_loss_arr_128_07, val_accuracy_arr_128_07 = train_model(\n    model_128_dropout_07, train_loader, val_loader, criterion, optimizer_128_dropout_07, num_epochs=epochs, device=device)\n\n# Eğitim sonuçlarını görselleştirme\nplot_training_curves(train_loss_arr_128_07, val_loss_arr_128_07, train_accuracy_arr_128_07, val_accuracy_arr_128_07)\nmetrics(\"model_128_dropout_07\", model_128_dropout_07, test_loader, criterion, device, label_mapping)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T19:36:40.964791Z","iopub.execute_input":"2024-10-23T19:36:40.965191Z","iopub.status.idle":"2024-10-23T20:06:00.011052Z","shell.execute_reply.started":"2024-10-23T19:36:40.965150Z","shell.execute_reply":"2024-10-23T20:06:00.009658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SGD Algoritmalı Model","metadata":{}},{"cell_type":"code","source":"# 128 Nöronlu SGD Model\nhidden_layers = [128]  # Gizli katmanlar\ndropout_rate = 0.5  # Dropout oranı\n\n# create_model fonksiyonu ile modeli oluştur\nmodel_128_sgd = create_model(input_size, output_size, hidden_layers, dropout_rate)\n\n# Modeli cihaza aktar\nmodel_128_sgd = model_128_sgd.to(device)\n\n# Kayıp fonksiyonu ve optimizer tanımlama (SGD)\noptimizer_128_sgd = torch.optim.SGD(model_128_sgd.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n\n# 128 nöronlu modelin eğitim aşaması (SGD ile)\ntrain_loss_arr_128_sgd, train_accuracy_arr_128_sgd, val_loss_arr_128_sgd, val_accuracy_arr_128_sgd = train_model(\n    model_128_sgd, train_loader, val_loader, criterion, optimizer_128_sgd, num_epochs=epochs, device=device)\n\n# Eğitim sonuçlarını görselleştirme\nplot_training_curves(train_loss_arr_128_sgd, val_loss_arr_128_sgd, train_accuracy_arr_128_sgd, val_accuracy_arr_128_sgd)\nmetrics(\"model_128_sgd\", model_128_sgd, test_loader, criterion, device, label_mapping)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T20:06:00.013130Z","iopub.execute_input":"2024-10-23T20:06:00.013557Z","iopub.status.idle":"2024-10-23T20:34:54.657073Z","shell.execute_reply.started":"2024-10-23T20:06:00.013514Z","shell.execute_reply":"2024-10-23T20:34:54.655711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# [128,512] Gizli Katmanlı Model","metadata":{}},{"cell_type":"code","source":"# 512 ve 128 Nöronlu Gizli Katmanlar\nhidden_layers = [128, 512]  # Gizli katmanlar\ndropout_rate = 0.5  # Dropout oranı\n\n# create_model fonksiyonu ile modeli oluştur\nmodel_512_128 = create_model(input_size, output_size, hidden_layers, dropout_rate)\n\n# Modeli cihaza aktar\nmodel_512_128 = model_512_128.to(device)\n\n# Kayıp fonksiyonu ve optimizer tanımlama\ncriterion = nn.CrossEntropyLoss()\noptimizer_512_128 = torch.optim.SGD(model_512_128.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n\n# Modelin eğitim aşaması\ntrain_loss_arr_512_128, train_accuracy_arr_512_128, val_loss_arr_512_128, val_accuracy_arr_512_128 = train_model(\n    model_512_128, train_loader, val_loader, criterion, optimizer_512_128, num_epochs=epochs, device=device)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-23T20:34:54.658847Z","iopub.execute_input":"2024-10-23T20:34:54.659236Z","iopub.status.idle":"2024-10-23T21:03:26.413698Z","shell.execute_reply.started":"2024-10-23T20:34:54.659192Z","shell.execute_reply":"2024-10-23T21:03:26.411963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Eğitim sonuçlarını görselleştirme\nplot_training_curves(train_loss_arr_512_128, val_loss_arr_512_128, train_accuracy_arr_512_128, val_accuracy_arr_512_128)\nmetrics(\"model_128_512\", model_512_128, test_loader, criterion, device, label_mapping)","metadata":{"execution":{"iopub.status.busy":"2024-10-23T21:03:26.415623Z","iopub.execute_input":"2024-10-23T21:03:26.416041Z","iopub.status.idle":"2024-10-23T21:03:40.633702Z","shell.execute_reply.started":"2024-10-23T21:03:26.416000Z","shell.execute_reply":"2024-10-23T21:03:40.632544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Sonuçları","metadata":{}},{"cell_type":"code","source":"all_result","metadata":{"execution":{"iopub.status.busy":"2024-10-23T21:03:40.635217Z","iopub.execute_input":"2024-10-23T21:03:40.635604Z","iopub.status.idle":"2024-10-23T21:03:40.652826Z","shell.execute_reply.started":"2024-10-23T21:03:40.635562Z","shell.execute_reply":"2024-10-23T21:03:40.651426Z"},"trusted":true},"execution_count":null,"outputs":[]}]}